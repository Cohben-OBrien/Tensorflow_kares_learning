{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T15:02:32.250879Z",
     "start_time": "2025-04-03T15:02:32.044922Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from cffi import model\n",
    "from keras import layers\n",
    "from keras.src.callbacks import early_stopping\n",
    "from keras.src.metrics.accuracy_metrics import accuracy\n",
    "from sympy import sequence, factor\n",
    "from tensorflow.python.eager.profiler import start\n",
    "from tensorflow.python.feature_column.utils import sequence_length_from_sparse_tensor\n",
    "from tensorflow.python.keras.backend import learning_phase"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:02:37.670566Z",
     "start_time": "2025-04-03T15:02:36.052081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ],
   "id": "7f2517b238805e13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:02:40.080906Z",
     "start_time": "2025-04-03T15:02:40.077728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 1\n",
    "dropout_rate = 0.2\n",
    "image_size = 64\n",
    "patch_size = 8\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "embedding_dim = 256\n",
    "num_blocks = 4\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {image_size ** 2}\")\n",
    "print(f\"Patches per images: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(num_patches ** 2) * 2}\")\n"
   ],
   "id": "7a90a683e0144f02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 64 X 64 = 4096\n",
      "Patch size: 8 X 8 = 4096\n",
      "Patches per images: 64\n",
      "Elements per patch (3 channels): 8192\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:02:45.208722Z",
     "start_time": "2025-04-03T15:02:45.205493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_classifier(blocks, positional_encoding=False):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    augmented = data_augmentation(inputs)\n",
    "\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    x = layers.Dense(units=embedding_dim)(patches)\n",
    "\n",
    "    if positional_encoding:\n",
    "        x = x + PositionalEmbedding(sequence_length=num_patches)(x)\n",
    "\n",
    "    x = blocks(x)\n",
    "\n",
    "    representation = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
    "\n",
    "    logits = layers.Dense(num_classes)(representation)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=logits)"
   ],
   "id": "67428c2f945dc408",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:02:51.061402Z",
     "start_time": "2025-04-03T15:02:51.058014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                 keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"Top_5\")],\n",
    "    )\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    _, acc, top_5 = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Top 5 accuracy: {top_5}\")\n",
    "\n",
    "    return history\n"
   ],
   "id": "961efcbec4f523f2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:03:01.996755Z",
     "start_time": "2025-04-03T15:02:53.942566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ],
   "id": "23c20ad8cc2bdffb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743692574.427606   38390 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:04:10.681602Z",
     "start_time": "2025-04-03T15:04:10.678335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, x):\n",
    "        patches = keras.ops.image.extract_patches(x, self.patch_size)\n",
    "        batch = keras.ops.shape(patches)[0]\n",
    "        num_patches = keras.ops.shape(patches)[1] * keras.ops.shape(patches)[2]\n",
    "        patch_dim = keras.ops.shape(patches)[3]\n",
    "        out = keras.ops.reshape(patches, (batch, num_patches, patch_dim))\n",
    "\n",
    "        return out"
   ],
   "id": "15837133c2da7195",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:04:17.979740Z",
     "start_time": "2025-04-03T15:04:17.976082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, initalizer=\"glorot_uniform\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if sequence_length is None:\n",
    "            raise ValueError(\"Sequence length cannot be None\")\n",
    "        self.sequence_length = int(sequence_length)\n",
    "        self.initializer = keras.initializers.get(initalizer)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = self.get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"initializer\": keras.initializers.serialize(self.initializer),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_size = input_shape[-1]\n",
    "        self.position_embedding = self.add_weight(\n",
    "            name=\"embedding\",\n",
    "            shape=[self.sequence_length, feature_size],\n",
    "            initializer=self.initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, start_index=0):\n",
    "        shape = keras.ops.shape(inputs)\n",
    "        feature_size = shape[-1]\n",
    "        sequence_length = shape[-2]\n",
    "\n",
    "        position_embedding = keras.ops.covert_to_tensor(self.position_embedding)\n",
    "        position_embedding = keras.ops.slice(\n",
    "            position_embedding,\n",
    "            (start_index, 0),\n",
    "            (self.sequence_length, feature_size)\n",
    "        )\n",
    "\n",
    "        return keras.ops.broadcast_to(position_embedding, shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ],
   "id": "b4deb97a18c20cb7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:04:23.759896Z",
     "start_time": "2025-04-03T15:04:23.756366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLPMixerLayers(layers.Layer):\n",
    "    def __init__(self, num_classes, hidden_units, dropout_rate, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.mlp1 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches, activation=\"gelu\"),\n",
    "                layers.Dense(units=num_patches),\n",
    "                layers.Dropout(rate=dropout_rate)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.mlp2 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches, activation=\"gelu\"),\n",
    "                layers.Dense(units=hidden_units),\n",
    "                layers.Dropout(rate=dropout_rate)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.normalize(inputs)\n",
    "\n",
    "        x_channels = keras.ops.transpose(x, axes=(0, 2, 1))\n",
    "\n",
    "        mlp1_outputs = self.mlp1(x_channels)\n",
    "        mlp1_outputs = keras.ops.transpose(mlp1_outputs, axes=(0, 2, 1))\n",
    "\n",
    "        x = mlp1_outputs + inputs\n",
    "\n",
    "        x_patches = self.normalize(x)\n",
    "\n",
    "        mlp2_outputs = self.mlp2(x_patches)\n",
    "\n",
    "        x = x + mlp2_outputs\n",
    "\n",
    "        return x\n",
    "\n"
   ],
   "id": "5a46a09f87114696",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:04:50.923444Z",
     "start_time": "2025-04-03T15:04:26.256361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlpmixer_blocks = keras.Sequential(\n",
    "    [\n",
    "        MLPMixerLayers(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)\n",
    "    ]\n",
    ")\n",
    "\n",
    "learning_rate = 0.005\n",
    "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
    "history = run_experiment(mlpmixer_classifier)\n"
   ],
   "id": "ac9196e00bf3039b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743692671.262757   49115 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - Top_5: 0.9252 - accuracy: 0.4860 - loss: 1.4514\n",
      "Accuracy: 0.4821000099182129\n",
      "Top 5 accuracy: 0.9247000217437744\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
